{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Fashion_MNIST_Kaggle_File.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kristina0614/Computer-Vision-Course/blob/main/Fashion_MNIST_Kaggle_File.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KP71MogWg4r2"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/doc/img/fashion-mnist-sprite.png\" width=\"500\" height=\"250\" align=\"center\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFBH7lKIg4r9"
      },
      "source": [
        "<br>\n",
        "<h1 style = \"font-size:30px; font-weight : bold; color : blue; text-align: center; border-radius: 10px 15px;\"> Fashion MNIST: Image Classification with Convolutional Neural Networks </h1>\n",
        "<br>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zpx1Rcvg4r-"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This is my first notebook on image classification using Convolutional Neural Networks. My motivation to create this notebook was to put in practice what I’ve learned in Kaggle’s Computer Vision course.\n",
        "\n",
        "I’ve built two CNN models, one simpler to serve as a baseline and one improved version, with more convolutional layers and the addition of dropouts for regularization.\n",
        "\n",
        "Validation Accuracy (20% of train data):\n",
        "\n",
        "- Baseline CNN: 91.86%\n",
        "- Improved CNN: 93.58%\n",
        "\n",
        "Test Accuracy:\n",
        "\n",
        "- Improved CNN: 93.94%\n",
        "\n",
        "To prepare the data, I used the preprocessing function found in [Gabriel Preda’s](https://www.kaggle.com/gpreda) notebook [‘CNN with Tensorflow|Keras for Fashion MNIST’](https://www.kaggle.com/gpreda/cnn-with-tensorflow-keras-for-fashion-mnist). \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89laAVD8g4r_"
      },
      "source": [
        "# <a id='0'>Content</a>\n",
        "\n",
        "- <a href='#1'>Dataset Information</a>  \n",
        "- <a href='#2'>Importing Packages and Exploring the Data</a>  \n",
        "- <a href='#3'>Baseline Model</a>  \n",
        "- <a href='#4'>Improved Model</a>\n",
        "- <a href='#5'>Predictions on the Test Set</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HIiym5Rg4sA"
      },
      "source": [
        "# <a id=\"1\">Dataset Information</a> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nx2QmJpGg4sA"
      },
      "source": [
        "### Context\n",
        "Fashion-MNIST is a dataset of Zalando's article images—consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n",
        "\n",
        "### Content\n",
        "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns. The first column consists of the class labels, and represents the article of clothing. The rest of the columns contain the pixel-values of the associated image.\n",
        "\n",
        "#### Labels\n",
        "Each training and test example is assigned to one of the following labels:\n",
        "\n",
        "- 0: T-shirt/top\n",
        "- 1: Trouser\n",
        "- 2: Pullover\n",
        "- 3: Dress\n",
        "- 4: Coat\n",
        "- 5: Sandal\n",
        "- 6: Shirt\n",
        "- 7: Sneaker\n",
        "- 8: Bag\n",
        "- 9: Ankle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2LElReEg4sB"
      },
      "source": [
        "## <center>If you find this notebook useful, support with an upvote!<center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eotbad2bg4sC"
      },
      "source": [
        "# <a id=\"2\">Importing Packages and Exploring the Data</a> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T02:39:50.314341Z",
          "iopub.execute_input": "2021-09-09T02:39:50.314725Z",
          "iopub.status.idle": "2021-09-09T02:39:55.397242Z",
          "shell.execute_reply.started": "2021-09-09T02:39:50.314644Z",
          "shell.execute_reply": "2021-09-09T02:39:55.396362Z"
        },
        "trusted": true,
        "id": "ISb4-HhRg4sD"
      },
      "source": [
        "import pandas as pd       \n",
        "import matplotlib as mat\n",
        "import matplotlib.pyplot as plt    \n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "import random\n",
        "import os\n",
        "\n",
        "from numpy.random import seed\n",
        "seed(42)\n",
        "\n",
        "random.seed(42)\n",
        "os.environ['PYTHONHASHSEED'] = str(42)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import callbacks\n",
        "from keras.models import Model\n",
        "\n",
        "from tensorflow.random import set_seed\n",
        "set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T02:39:55.398669Z",
          "iopub.execute_input": "2021-09-09T02:39:55.39899Z",
          "iopub.status.idle": "2021-09-09T02:40:02.862392Z",
          "shell.execute_reply.started": "2021-09-09T02:39:55.398962Z",
          "shell.execute_reply": "2021-09-09T02:40:02.861481Z"
        },
        "trusted": true,
        "id": "jlwReA_bg4sG"
      },
      "source": [
        "df_train = pd.read_csv('../input/fashionmnist/fashion-mnist_train.csv')\n",
        "df_test = pd.read_csv('../input/fashionmnist/fashion-mnist_test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T02:40:02.865594Z",
          "iopub.execute_input": "2021-09-09T02:40:02.865866Z",
          "iopub.status.idle": "2021-09-09T02:40:02.902642Z",
          "shell.execute_reply.started": "2021-09-09T02:40:02.86584Z",
          "shell.execute_reply": "2021-09-09T02:40:02.901742Z"
        },
        "trusted": true,
        "id": "6m2Sbj03g4sG"
      },
      "source": [
        "df_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T02:40:02.904192Z",
          "iopub.execute_input": "2021-09-09T02:40:02.90454Z",
          "iopub.status.idle": "2021-09-09T02:40:02.926768Z",
          "shell.execute_reply.started": "2021-09-09T02:40:02.904505Z",
          "shell.execute_reply": "2021-09-09T02:40:02.925854Z"
        },
        "trusted": true,
        "id": "3_v0eElvg4sH"
      },
      "source": [
        "df_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5v3cR_-g4sH"
      },
      "source": [
        "Both datasets have 785 columns. The first column presents the class labels for each article of clothing, while the remaining columns contains the pixel values. As described in the dataset information, each image is 28 pixels in height and 28 pixels in width (for a total of 784 pixels).\n",
        "\n",
        "We will separate the labels from each dataset and reshape their columns from 784 columns to a 28x28x1 format (Height, Width and Number of Channels) using the preprocessing function found in Preda’s notebook.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T02:40:02.92806Z",
          "iopub.execute_input": "2021-09-09T02:40:02.928416Z",
          "iopub.status.idle": "2021-09-09T02:40:02.933963Z",
          "shell.execute_reply.started": "2021-09-09T02:40:02.92838Z",
          "shell.execute_reply": "2021-09-09T02:40:02.932805Z"
        },
        "trusted": true,
        "id": "hZ-ydSOLg4sI"
      },
      "source": [
        "#https://www.kaggle.com/gpreda/cnn-with-tensorflow-keras-for-fashion-mnist\n",
        "\n",
        "#784 pixels(columns) -> 28x28 (height and width in pixels)\n",
        "IMG_ROWS = 28\n",
        "IMG_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "\n",
        "def data_preprocessing(raw):\n",
        "    out_y = keras.utils.to_categorical(raw.label, NUM_CLASSES) \n",
        "    num_images = raw.shape[0]\n",
        "    x_as_array = raw.values[:,1:]\n",
        "    \n",
        "    # Reshaping to (num_images, Width, Height, Colour Channels)\n",
        "    x_shaped_array = x_as_array.reshape(num_images, IMG_ROWS, IMG_COLS, 1)\n",
        "    \n",
        "    #Normalizing the values (pixel-value is an integer between 0 and 255)\n",
        "    out_x = x_shaped_array / 255\n",
        "    return out_x, out_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T02:40:02.935283Z",
          "iopub.execute_input": "2021-09-09T02:40:02.935783Z",
          "iopub.status.idle": "2021-09-09T02:40:03.112313Z",
          "shell.execute_reply.started": "2021-09-09T02:40:02.935738Z",
          "shell.execute_reply": "2021-09-09T02:40:03.111448Z"
        },
        "trusted": true,
        "id": "BcvdEDIWg4sI"
      },
      "source": [
        "X, Y = data_preprocessing(df_train)\n",
        "X_test, Y_test = data_preprocessing(df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T02:40:03.113565Z",
          "iopub.execute_input": "2021-09-09T02:40:03.113939Z",
          "iopub.status.idle": "2021-09-09T02:40:03.119922Z",
          "shell.execute_reply.started": "2021-09-09T02:40:03.113901Z",
          "shell.execute_reply": "2021-09-09T02:40:03.118939Z"
        },
        "trusted": true,
        "id": "4miSk90ig4sJ"
      },
      "source": [
        "print('X_train shape: ', X.shape)\n",
        "print('X_test shape: ', X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rLxZNUCg4sJ"
      },
      "source": [
        "Let’s plot a few samples from each dataset to see what kind of images we have."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T02:40:03.123261Z",
          "iopub.execute_input": "2021-09-09T02:40:03.123753Z",
          "iopub.status.idle": "2021-09-09T02:40:04.762633Z",
          "shell.execute_reply.started": "2021-09-09T02:40:03.123715Z",
          "shell.execute_reply": "2021-09-09T02:40:04.761602Z"
        },
        "trusted": true,
        "id": "jQag5ec9g4sK"
      },
      "source": [
        "labels_list = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal'\n",
        "              ,'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "plt.figure(figsize=(12,12))\n",
        "\n",
        "for i in range(0, 36):\n",
        "    plt.subplot(6,6,i + 1)\n",
        "    plt.imshow(X[i], cmap=plt.get_cmap('gray'))\n",
        "    plt.title(labels_list[df_train.iloc[i, 0]])\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T02:40:04.764604Z",
          "iopub.execute_input": "2021-09-09T02:40:04.764938Z",
          "iopub.status.idle": "2021-09-09T02:40:06.442594Z",
          "shell.execute_reply.started": "2021-09-09T02:40:04.764905Z",
          "shell.execute_reply": "2021-09-09T02:40:06.441762Z"
        },
        "trusted": true,
        "id": "ppTJYvAkg4sK"
      },
      "source": [
        "plt.figure(figsize=(12,12))\n",
        "\n",
        "for i in range(0, 36):\n",
        "    plt.subplot(6,6,i + 1)\n",
        "    plt.imshow(X_test[i], cmap=plt.get_cmap('gray'))\n",
        "    plt.title(labels_list[df_test.iloc[i, 0]])\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iIGY4Hcg4sK"
      },
      "source": [
        "Before we move on to the modelling stage, we will check the how many samples each class has."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T02:40:06.443831Z",
          "iopub.execute_input": "2021-09-09T02:40:06.444353Z",
          "iopub.status.idle": "2021-09-09T02:40:06.455782Z",
          "shell.execute_reply.started": "2021-09-09T02:40:06.444305Z",
          "shell.execute_reply": "2021-09-09T02:40:06.454842Z"
        },
        "trusted": true,
        "id": "FvhhH1CDg4sL"
      },
      "source": [
        "print('Train Set Class Distribution:\\n')\n",
        "print(df_train['label'].value_counts())\n",
        "\n",
        "print('\\nTest Set Class Distribution:\\n')\n",
        "print(df_test['label'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euWz73VJg4sL"
      },
      "source": [
        "Both datasets are perfectly balanced, with the samples equally distributed among the classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaVUUkXjg4sL"
      },
      "source": [
        "# <a id=\"3\">Baseline Model</a> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hc7RHHFqg4sM"
      },
      "source": [
        "First, we will split the train dataset into train/validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T02:40:06.457231Z",
          "iopub.execute_input": "2021-09-09T02:40:06.457712Z",
          "iopub.status.idle": "2021-09-09T02:40:07.825504Z",
          "shell.execute_reply.started": "2021-09-09T02:40:06.457672Z",
          "shell.execute_reply": "2021-09-09T02:40:07.824587Z"
        },
        "trusted": true,
        "id": "A-w3Ax42g4sM"
      },
      "source": [
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.2, random_state = 42\n",
        "                                                    , stratify = Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuUnwYdMg4sM"
      },
      "source": [
        "Now, let's create our baseline model with two convolutional layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T02:40:07.826894Z",
          "iopub.execute_input": "2021-09-09T02:40:07.827261Z",
          "iopub.status.idle": "2021-09-09T02:40:07.83682Z",
          "shell.execute_reply.started": "2021-09-09T02:40:07.827223Z",
          "shell.execute_reply": "2021-09-09T02:40:07.834214Z"
        },
        "trusted": true,
        "id": "o2Z_l9-Cg4sM"
      },
      "source": [
        "def get_model():\n",
        "    \n",
        "    #Input shape = [width, height, color channels]\n",
        "    inputs = layers.Input(shape=(IMG_ROWS, IMG_COLS, 1))\n",
        "    \n",
        "    # Block One\n",
        "    x = layers.BatchNormalization()(inputs)\n",
        "    x = layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "\n",
        "    # Block Two\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "\n",
        "    # Head\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(64, activation='relu')(x)\n",
        "    \n",
        "    #Final Layer (Output)\n",
        "    output = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "    \n",
        "    model = keras.Model(inputs=[inputs], outputs=output)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T02:40:07.838138Z",
          "iopub.execute_input": "2021-09-09T02:40:07.838516Z",
          "iopub.status.idle": "2021-09-09T02:40:07.84578Z",
          "shell.execute_reply.started": "2021-09-09T02:40:07.838478Z",
          "shell.execute_reply": "2021-09-09T02:40:07.844928Z"
        },
        "trusted": true,
        "id": "frolF77Og4sN"
      },
      "source": [
        "#Setting early_stopping callback\n",
        "early_stopping = callbacks.EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=15,\n",
        "    min_delta=0.0000001,\n",
        "    restore_best_weights=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T02:40:07.84706Z",
          "iopub.execute_input": "2021-09-09T02:40:07.847468Z",
          "iopub.status.idle": "2021-09-09T02:40:09.79736Z",
          "shell.execute_reply.started": "2021-09-09T02:40:07.847433Z",
          "shell.execute_reply": "2021-09-09T02:40:09.785784Z"
        },
        "trusted": true,
        "id": "-vuCF696g4sN"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "\n",
        "model_1 = get_model()\n",
        "model_1.compile(loss='categorical_crossentropy'\n",
        "              , optimizer = keras.optimizers.Adam(learning_rate=0.001), metrics='accuracy')\n",
        "\n",
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O0tilZFg4sN"
      },
      "source": [
        "Let’s train our baseline model and use the validation set for a first assessment of its performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2021-09-09T02:40:09.799031Z",
          "iopub.execute_input": "2021-09-09T02:40:09.799417Z",
          "iopub.status.idle": "2021-09-09T02:41:56.902756Z",
          "shell.execute_reply.started": "2021-09-09T02:40:09.79938Z",
          "shell.execute_reply": "2021-09-09T02:41:56.90187Z"
        },
        "trusted": true,
        "id": "l8I2ZYGng4sO"
      },
      "source": [
        "history = model_1.fit(X_train, Y_train,\n",
        "          batch_size = 128, epochs = 100,\n",
        "          validation_data=(X_val, Y_val),\n",
        "          callbacks=[early_stopping]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T02:41:56.905521Z",
          "iopub.execute_input": "2021-09-09T02:41:56.905807Z",
          "iopub.status.idle": "2021-09-09T02:41:57.163365Z",
          "shell.execute_reply.started": "2021-09-09T02:41:56.905779Z",
          "shell.execute_reply": "2021-09-09T02:41:57.162574Z"
        },
        "trusted": true,
        "id": "r55hkCjRg4sO"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(20,8))\n",
        "sns.lineplot(x = history.epoch, y = history.history['loss'])\n",
        "sns.lineplot(x = history.epoch, y = history.history['val_loss'])\n",
        "ax.set_title('Learning Curve (Loss)')\n",
        "ax.set_ylabel('Loss')\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.legend(['train', 'val'], loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T02:41:57.164667Z",
          "iopub.execute_input": "2021-09-09T02:41:57.165006Z",
          "iopub.status.idle": "2021-09-09T02:41:57.39025Z",
          "shell.execute_reply.started": "2021-09-09T02:41:57.16497Z",
          "shell.execute_reply": "2021-09-09T02:41:57.389193Z"
        },
        "trusted": true,
        "id": "Qiy3XAjkg4sO"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(20,8))\n",
        "sns.lineplot(x = history.epoch, y = history.history['accuracy'])\n",
        "sns.lineplot(x = history.epoch, y = history.history['val_accuracy'])\n",
        "ax.set_title('Learning Curve (Accuracy)')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.legend(['train', 'val'], loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T02:41:57.391732Z",
          "iopub.execute_input": "2021-09-09T02:41:57.392085Z",
          "iopub.status.idle": "2021-09-09T02:41:58.322124Z",
          "shell.execute_reply.started": "2021-09-09T02:41:57.392047Z",
          "shell.execute_reply": "2021-09-09T02:41:58.321131Z"
        },
        "trusted": true,
        "id": "YSbDtfzxg4sP"
      },
      "source": [
        "score = model_1.evaluate(X_val, Y_val, verbose = 0)\n",
        "print('Val loss:', score[0])\n",
        "print('Val accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gljehwJWg4sP"
      },
      "source": [
        "Our baseline model reached a validation accuracy of 91.86%, which seems to be good. However, when we look at the learning curves (specifically the loss curves), we can see that the model is overfitting right after the first 5 epochs. This shows us that the addition of regularization methods, such as dropout layers, can probably improve our model’s performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oxp6moUIg4sP"
      },
      "source": [
        "# <a id=\"4\">Improved Model</a> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_ZO0UF4g4sQ"
      },
      "source": [
        "Now, let’s build a new, better model. As previously stated, the solely addition of dropout layers could improve the validation accuracy. I’ve tested this and found a validation accuracy of 93,36% (not shown in this notebook). There is still room to build a more robust CNN. After a few tests, I’ve decided to include a third Conv Block, with 2 convolutional layers. Let’s check the performance of this new model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T02:41:58.323594Z",
          "iopub.execute_input": "2021-09-09T02:41:58.323953Z",
          "iopub.status.idle": "2021-09-09T02:41:58.33455Z",
          "shell.execute_reply.started": "2021-09-09T02:41:58.323914Z",
          "shell.execute_reply": "2021-09-09T02:41:58.333585Z"
        },
        "trusted": true,
        "id": "foyiUKUvg4sQ"
      },
      "source": [
        "def get_model2():\n",
        "    \n",
        "    #Input shape = [width, height, color channels]\n",
        "    inputs = layers.Input(shape=(IMG_ROWS, IMG_COLS, 1))\n",
        "    \n",
        "    # Block One\n",
        "    x = layers.BatchNormalization()(inputs)\n",
        "    x = layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    # Block Two\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    # Block Three\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same')(x)\n",
        "    x = layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    # Head\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(64, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    \n",
        "    #Final Layer (Output)\n",
        "    output = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "    \n",
        "    model = keras.Model(inputs=[inputs], outputs=output)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T02:41:58.33611Z",
          "iopub.execute_input": "2021-09-09T02:41:58.336878Z",
          "iopub.status.idle": "2021-09-09T02:41:58.465147Z",
          "shell.execute_reply.started": "2021-09-09T02:41:58.336828Z",
          "shell.execute_reply": "2021-09-09T02:41:58.464369Z"
        },
        "trusted": true,
        "id": "-85_tZw2g4sQ"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "\n",
        "model_2 = get_model2()\n",
        "model_2.compile(loss='categorical_crossentropy'\n",
        "              , optimizer = keras.optimizers.Adam(learning_rate=0.001), metrics='accuracy')\n",
        "\n",
        "model_2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2021-09-09T02:41:58.466461Z",
          "iopub.execute_input": "2021-09-09T02:41:58.466793Z",
          "iopub.status.idle": "2021-09-09T02:45:38.575745Z",
          "shell.execute_reply.started": "2021-09-09T02:41:58.466757Z",
          "shell.execute_reply": "2021-09-09T02:45:38.574959Z"
        },
        "trusted": true,
        "id": "tSZDsDZ1g4sQ"
      },
      "source": [
        "history = model_2.fit(X_train, Y_train,\n",
        "          batch_size = 128, epochs = 100,\n",
        "          validation_data=(X_val, Y_val),\n",
        "          callbacks=[early_stopping]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T02:45:38.577089Z",
          "iopub.execute_input": "2021-09-09T02:45:38.577442Z",
          "iopub.status.idle": "2021-09-09T02:45:38.781328Z",
          "shell.execute_reply.started": "2021-09-09T02:45:38.577406Z",
          "shell.execute_reply": "2021-09-09T02:45:38.780289Z"
        },
        "trusted": true,
        "id": "bM0Y6J7hg4sR"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(20,8))\n",
        "sns.lineplot(x = history.epoch, y = history.history['loss'])\n",
        "sns.lineplot(x = history.epoch, y = history.history['val_loss'])\n",
        "ax.set_title('Learning Curve (Loss)')\n",
        "ax.set_ylabel('Loss')\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.legend(['train', 'test'], loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T02:45:38.78501Z",
          "iopub.execute_input": "2021-09-09T02:45:38.785388Z",
          "iopub.status.idle": "2021-09-09T02:45:39.019855Z",
          "shell.execute_reply.started": "2021-09-09T02:45:38.785359Z",
          "shell.execute_reply": "2021-09-09T02:45:39.019058Z"
        },
        "trusted": true,
        "id": "BWZJP6iRg4sR"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(20,8))\n",
        "sns.lineplot(x = history.epoch, y = history.history['accuracy'])\n",
        "sns.lineplot(x = history.epoch, y = history.history['val_accuracy'])\n",
        "ax.set_title('Learning Curve (Accuracy)')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.legend(['train', 'test'], loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T02:45:39.022737Z",
          "iopub.execute_input": "2021-09-09T02:45:39.023019Z",
          "iopub.status.idle": "2021-09-09T02:45:40.096059Z",
          "shell.execute_reply.started": "2021-09-09T02:45:39.022993Z",
          "shell.execute_reply": "2021-09-09T02:45:40.095067Z"
        },
        "trusted": true,
        "id": "b4wAiDM2g4sR"
      },
      "source": [
        "score = model_2.evaluate(X_val, Y_val, verbose = 0)\n",
        "print('Val loss:', score[0])\n",
        "print('Val accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RwviuiYg4sR"
      },
      "source": [
        "The effect of the dropout layers can be observed by looking at the learning curves. The validation loss decreases for a longer period, reaching lower values than the one found in our baseline model, and it stabilizes at a certain point. The new model reached a validation accuracy of 93,58%, beating the baseline model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4TkP6qkg4sS"
      },
      "source": [
        "# <a id=\"5\">Predictions on the Test Set</a> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHsemQhug4sS"
      },
      "source": [
        "Now, let’s use our model to make predictions on the test set and check our results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T02:45:40.097587Z",
          "iopub.execute_input": "2021-09-09T02:45:40.097961Z",
          "iopub.status.idle": "2021-09-09T02:45:40.816161Z",
          "shell.execute_reply.started": "2021-09-09T02:45:40.097924Z",
          "shell.execute_reply": "2021-09-09T02:45:40.815258Z"
        },
        "trusted": true,
        "id": "dKAGevYNg4sS"
      },
      "source": [
        "predictions = model_2.predict(X_test)\n",
        "pred_labels = predictions.argmax(axis=-1) #From probabilities to class labels\n",
        "print(\"Test Accuracy: \", accuracy_score(df_test['label'], pred_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T02:45:40.819134Z",
          "iopub.execute_input": "2021-09-09T02:45:40.819403Z",
          "iopub.status.idle": "2021-09-09T02:45:40.852477Z",
          "shell.execute_reply.started": "2021-09-09T02:45:40.819374Z",
          "shell.execute_reply": "2021-09-09T02:45:40.851585Z"
        },
        "trusted": true,
        "id": "iBvtupONg4sS"
      },
      "source": [
        "print(metrics.classification_report(df_test['label'], pred_labels, target_names=labels_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clStt52jg4sT"
      },
      "source": [
        "We were able to reach a test accuracy of 93.94% with the new model. As seen in the classification report, our model was almost perfect at predicting Trousers. The performance in predicting Sandals and Bags is also noticeable, with a 99% F1-Score. On the other hand, the model had some difficulties in predicting Shirts, with a Recall around 80% and less than 85% in Precision. This will be explored in a future version of this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfEuKAngg4sT"
      },
      "source": [
        "## <center>If you find this notebook useful, support with an upvote!<center>"
      ]
    }
  ]
}